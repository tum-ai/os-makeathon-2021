{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](images/Makeathon_Logo.png)\n",
    "# Notebook 4 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook you'll get started with tackling regression problems. What are regression problems? In essence, problems where you have to predict a continuous value (like a price or a temperature) as opposed to a class for example. In this notebook we'll try to predict house prices given some information on each house (number of bedrooms, garage or not etc.)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christoph/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Import ML tools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link to dataset: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "# Load and preprocess data\n",
    "train_data = pd.read_csv('./house_prices/train.csv')\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "\n",
    "y = train_data.SalePrice\n",
    "X = train_data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X.values, y.values, test_size=0.25)\n",
    "my_imputer = Imputer()\n",
    "train_X = my_imputer.fit_transform(train_X)\n",
    "test_X = my_imputer.fit_transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For regression problems, decision trees, not neural networks, are oftentimes the tool of choise. Why? In many use cases, decision tree-based architectures perform similarly well whilst being easier to train and better interpretable. So let's test a tree!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Decision Trees : 27088.09315068493\n"
     ]
    }
   ],
   "source": [
    "# Load, train, and test model\n",
    "decision_model = DecisionTreeRegressor()  \n",
    "decision_model.fit(train_X, train_y) \n",
    "predicted_decision_trees = decision_model.predict(test_X)\n",
    "print (\"Mean Absolute Error Decision Trees :\", mean_absolute_error(test_y, predicted_decision_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 395000$| Real: 410000$| Diff: -15000$\n",
      "Pred: 230000$| Real: 261500$| Diff: -31500$\n",
      "Pred: 124000$| Real: 135000$| Diff: -11000$\n",
      "Pred: 188000$| Real: 150000$| Diff: 38000$\n",
      "Pred: 156500$| Real: 185750$| Diff: -29250$\n",
      "Pred: 186500$| Real: 177000$| Diff: 9500$\n",
      "Pred: 82500$| Real: 175500$| Diff: -93000$\n",
      "Pred: 127000$| Real: 153000$| Diff: -26000$\n",
      "Pred: 125500$| Real: 112000$| Diff: 13500$\n",
      "Pred: 180000$| Real: 149000$| Diff: 31000$\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the results\n",
    "for i in range(10):\n",
    "    y_hat = decision_model.predict(test_X[:10])\n",
    "    out = \"Pred: {}$| Real: {}$| Diff: {}$\".format(int(y_hat[i]), int(test_y[i]), int(y_hat[i]-test_y[i]))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you've seen, decision trees are very easy to train and seem to have sufficient predictive power. At least for predicting house prices it seems ... <br>**\n",
    "\n",
    "**However, there is one major problem with decision trees: They tend to overfit. This is why Random Forests (a lot of decision trees making predictions + taking the average prediction) are oftentimes the better choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error Random Forest: 18295.54722261151\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "forest_model.fit(train_X, train_y )\n",
    "predicted_random_forest = forest_model.predict(test_X)\n",
    "print(\"Mean Absolute Error Random Forest:\", mean_absolute_error(test_y, predicted_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 367638$| Real: 410000$| Diff: -42361$\n",
      "Pred: 241377$| Real: 261500$| Diff: -20122$\n",
      "Pred: 137441$| Real: 135000$| Diff: 2441$\n",
      "Pred: 151238$| Real: 150000$| Diff: 1238$\n",
      "Pred: 164177$| Real: 185750$| Diff: -21572$\n",
      "Pred: 153651$| Real: 177000$| Diff: -23348$\n",
      "Pred: 164973$| Real: 175500$| Diff: -10526$\n",
      "Pred: 139116$| Real: 153000$| Diff: -13883$\n",
      "Pred: 117771$| Real: 112000$| Diff: 5771$\n",
      "Pred: 163035$| Real: 149000$| Diff: 14035$\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y_hat = forest_model.predict(test_X[:10])\n",
    "    out = \"Pred: {}$| Real: {}$| Diff: {}$\".format(int(y_hat[i]), int(test_y[i]), int(y_hat[i]-test_y[i]))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looks quite precise! Of course, as shown in the NLP-Notebook, you could now use widgets for this type of problem too to have a nice little UI to interact with your regression model of choice.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
